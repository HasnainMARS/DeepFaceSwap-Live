{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33031298",
   "metadata": {},
   "source": [
    "## üîΩ Download ArcFace Model Automatically\n",
    "\n",
    "If the ArcFace model is not found locally, the following script will automatically download it from Hugging Face:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fbc588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArcFace model not found, downloading...\n",
      "Downloaded ArcFace ONNX model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "ARC_URL = \"https://huggingface.co/garavv/arcface-onnx/resolve/main/arc.onnx?download=true\"\n",
    "ARC_LOCAL = r\"C:\\Users\\Hasnain\\Desktop\\DeepFaceSwap\\model\\arcface.onnx\"\n",
    "\n",
    "def download_arcface():\n",
    "    if not os.path.exists(ARC_LOCAL):\n",
    "        print(\"ArcFace model not found, downloading...\")\n",
    "        resp = requests.get(ARC_URL, stream=True)\n",
    "        if resp.status_code == 200:\n",
    "            with open(ARC_LOCAL, \"wb\") as f:\n",
    "                for chunk in resp.iter_content(1024 * 1024):\n",
    "                    f.write(chunk)\n",
    "            print(\"Downloaded ArcFace ONNX model.\")\n",
    "        else:\n",
    "            raise RuntimeError(f\"Failed to download ArcFace model, status code {resp.status_code}\")\n",
    "\n",
    "# Usage in your main script\n",
    "download_arcface()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fddabf",
   "metadata": {},
   "source": [
    "## üñåÔ∏è Poisson Blending (Seamless Face Swap)\n",
    "\n",
    "This function uses **OpenCV‚Äôs `cv2.seamlessClone`** to blend the swapped face into the target image smoothly, avoiding harsh edges or ghosting artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54d2c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_blend(full, patch, box, blur_sigma=15, mode=cv2.NORMAL_CLONE):\n",
    "    \"\"\"\n",
    "    Poisson (seamless) blend 'patch' into 'full' inside the rectangle 'box'.\n",
    "    box = (x1, y1, x2, y2)\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = box\n",
    "    H, W = y2 - y1, x2 - x1\n",
    "\n",
    "    # 1) Resize patch to box size\n",
    "    src = cv2.resize(patch, (W, H))\n",
    "\n",
    "    # 2) Build a 1-channel 8-bit mask same size as src (white = keep, black = ignore)\n",
    "    mask = np.ones((H, W), dtype=np.uint8) * 255\n",
    "    if blur_sigma > 0:\n",
    "        mask = cv2.GaussianBlur(mask, (0, 0), blur_sigma)\n",
    "\n",
    "    # 3) Place src over a black canvas the size of full image\n",
    "    src_canvas = np.zeros_like(full)\n",
    "    src_canvas[y1:y2, x1:x2] = src\n",
    "\n",
    "    # 4) Place mask over a black canvas too (must be 1-channel 8-bit)\n",
    "    mask_canvas = np.zeros(full.shape[:2], dtype=np.uint8)\n",
    "    mask_canvas[y1:y2, x1:x2] = mask\n",
    "\n",
    "    # 5) Choose a center for seamlessClone (must lie INSIDE the mask region)\n",
    "    center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "\n",
    "    # 6) Poisson blend\n",
    "    blended = cv2.seamlessClone(src_canvas, full, mask_canvas, center, mode)\n",
    "    return blended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f2a2789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = poisson_blend(full, swapped, tgt_box, blur_sigma=15, mode=cv2.NORMAL_CLONE)\n",
    "cv2.imwrite(OUTPUT_IMAGE, final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109212f7",
   "metadata": {},
   "source": [
    "## üß™ Environment Test Script (ONNX + ONNXRuntime)\n",
    "\n",
    "Before running the full face swap pipeline, it‚Äôs useful to test whether **ONNXRuntime** is correctly set up with CUDA or CPU.  \n",
    "This script builds a tiny **dummy ONNX model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6345093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking ONNXRuntime providers...\n",
      "Available providers: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "‚úÖ Using provider: CUDAExecutionProvider\n",
      "üîß Input : [[1. 2. 3.]]\n",
      "üì¶ Output: [[1. 2. 3.]]\n",
      "üéâ Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "print(\"üîç Checking ONNXRuntime providers...\")\n",
    "print(\"Available providers:\", ort.get_available_providers())\n",
    "\n",
    "# Pick CUDA if available, otherwise CPU\n",
    "provider = \"CUDAExecutionProvider\" if \"CUDAExecutionProvider\" in ort.get_available_providers() else \"CPUExecutionProvider\"\n",
    "print(f\"‚úÖ Using provider: {provider}\")\n",
    "\n",
    "# Build a dummy ONNX model with low IR/opset version\n",
    "X = onnx.helper.make_tensor_value_info(\"input\", onnx.TensorProto.FLOAT, [1, 3])\n",
    "Y = onnx.helper.make_tensor_value_info(\"output\", onnx.TensorProto.FLOAT, [1, 3])\n",
    "node = onnx.helper.make_node(\"Identity\", inputs=[\"input\"], outputs=[\"output\"])\n",
    "graph = onnx.helper.make_graph([node], \"IdentityGraph\", [X], [Y])\n",
    "model = onnx.helper.make_model(\n",
    "    graph,\n",
    "    producer_name=\"test\",\n",
    "    ir_version=7,  # <= 9 supported by your ORT\n",
    "    opset_imports=[onnx.helper.make_opsetid(\"\", 9)]\n",
    ")\n",
    "\n",
    "# Save model\n",
    "onnx.save(model, \"dummy.onnx\")\n",
    "\n",
    "# Load into session\n",
    "session = ort.InferenceSession(\"dummy.onnx\", providers=[provider])\n",
    "\n",
    "# Test inference\n",
    "inp = np.array([[1.0, 2.0, 3.0]], dtype=np.float32)\n",
    "out = session.run(None, {\"input\": inp})[0]\n",
    "\n",
    "print(\"üîß Input :\", inp)\n",
    "print(\"üì¶ Output:\", out)\n",
    "print(\"üéâ Test completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133ac65",
   "metadata": {},
   "source": [
    "## üé• Real-Time Face Swap (Webcam Demo)\n",
    "\n",
    "This script runs **SimSwap ONNX** + **ArcFace ONNX** with OpenCV and MediaPipe to perform **real-time face swapping** from your webcam.  \n",
    "\n",
    "### üìå Features\n",
    "- Uses **ArcFace** to extract identity embedding from a source image.  \n",
    "- Uses **SimSwap ONNX** (`simswap_256.onnx`) to generate the swapped face.  \n",
    "- Supports two blending methods:\n",
    "  - **Poisson blending** (smooth, natural look using `cv2.seamlessClone`)  \n",
    "  - **Feather blending** (lighter but less realistic).  \n",
    "- Works in **real-time** on CUDA (`CUDAExecutionProvider`) or CPU fallback.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529dfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# ========= EDIT THESE PATHS =========\n",
    "# replace username with your real username\n",
    "SIMSWAP_MODEL = r\"C:\\Users\\username\\Desktop\\DeepFaceSwap\\model\\simswap_256.onnx\"\n",
    "ARCFACE_MODEL = r\"C:\\Users\\username\\Desktop\\DeepFaceSwap\\model\\arcface.onnx\"\n",
    "SOURCE_IMAGE  = r\"C:\\Users\\username\\Desktop\\DeepFaceSwap\\source.jpg\"  # identity\n",
    "# ====================================\n",
    "\n",
    "BLEND_MODE = \"poisson\"   # \"feather\" or \"poisson\"\n",
    "\n",
    "# ---------- Face utils ----------\n",
    "def detect_and_crop(img):\n",
    "    with mp.solutions.face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.6) as det:\n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        res = det.process(rgb)\n",
    "        if not res.detections:\n",
    "            return None, None\n",
    "        b = res.detections[0].location_data.relative_bounding_box\n",
    "        H, W = img.shape[:2]\n",
    "        x, y, w, h = int(b.xmin*W), int(b.ymin*H), int(b.width*W), int(b.height*H)\n",
    "        s = int(max(w, h) * 1.6)\n",
    "        cx, cy = x + w//2, y + h//2\n",
    "        x1, y1 = max(0, cx - s//2), max(0, cy - s//2)\n",
    "        x2, y2 = min(W, cx + s//2), min(H, cy + s//2)\n",
    "        return img[y1:y2, x1:x2].copy(), (x1, y1, x2, y2)\n",
    "\n",
    "def preprocess_face_256(bgr):\n",
    "    im = cv2.resize(bgr, (256, 256)).astype(np.float32) / 255.0\n",
    "    return np.transpose(im, (2, 0, 1))[None, ...]\n",
    "\n",
    "def preprocess_arcface_NHWC(bgr):\n",
    "    im = cv2.resize(bgr, (112, 112))\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    im = (im - 127.5) / 128.0\n",
    "    return im[None, ...]\n",
    "\n",
    "def postprocess_face(out_tensor):\n",
    "    out = out_tensor[0] if out_tensor.ndim == 4 else out_tensor\n",
    "    out = np.transpose(out, (1, 2, 0))\n",
    "    out = (np.clip(out, 0, 1) if out.max() <= 1.5 else np.clip(out/255.0, 0, 1)) * 255\n",
    "    return out.astype(np.uint8)\n",
    "\n",
    "def feather_blend(full, patch, box, feather=20):\n",
    "    x1, y1, x2, y2 = box\n",
    "    H, W = y2 - y1, x2 - x1\n",
    "    patch = cv2.resize(patch, (W, H))\n",
    "    mask = np.ones((H, W), dtype=np.float32)\n",
    "    mask = cv2.GaussianBlur(mask, (0, 0), feather)\n",
    "    mask /= (mask.max() + 1e-6)\n",
    "    mask = mask[..., None]\n",
    "    roi = full[y1:y2, x1:x2].astype(np.float32)\n",
    "    blended = (roi * (1.0 - mask) + patch.astype(np.float32) * mask).astype(np.uint8)\n",
    "    out = full.copy()\n",
    "    out[y1:y2, x1:x2] = blended\n",
    "    return out\n",
    "\n",
    "def poisson_blend(full, patch, box, blur_sigma=15, mode=cv2.NORMAL_CLONE):\n",
    "    x1, y1, x2, y2 = box\n",
    "    H, W = y2 - y1, x2 - x1\n",
    "    src = cv2.resize(patch, (W, H))\n",
    "    mask = np.ones((H, W), dtype=np.uint8) * 255\n",
    "    if blur_sigma > 0:\n",
    "        mask = cv2.GaussianBlur(mask, (0, 0), blur_sigma)\n",
    "    src_canvas = np.zeros_like(full)\n",
    "    src_canvas[y1:y2, x1:x2] = src\n",
    "    mask_canvas = np.zeros(full.shape[:2], dtype=np.uint8)\n",
    "    mask_canvas[y1:y2, x1:x2] = mask\n",
    "    center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "    blended = cv2.seamlessClone(src_canvas, full, mask_canvas, center, mode)\n",
    "    return blended\n",
    "\n",
    "# ---------- Setup models ----------\n",
    "providers = [\"CUDAExecutionProvider\"] if \"CUDAExecutionProvider\" in ort.get_available_providers() else [\"CPUExecutionProvider\"]\n",
    "print(\"Using providers:\", providers)\n",
    "\n",
    "ss = ort.InferenceSession(SIMSWAP_MODEL, providers=providers)\n",
    "ss_face_in, ss_id_in, ss_out_name = \"input\", \"onnx::Gemm_1\", \"output\"\n",
    "af = ort.InferenceSession(ARCFACE_MODEL, providers=providers)\n",
    "af_in_name, af_out_name = \"input_1\", \"embedding\"\n",
    "\n",
    "# ---------- Precompute identity embedding ----------\n",
    "src_img = cv2.imread(SOURCE_IMAGE)\n",
    "src_face, _ = detect_and_crop(src_img)\n",
    "src_in = preprocess_arcface_NHWC(src_face)\n",
    "emb = af.run([af_out_name], {af_in_name: src_in})[0]\n",
    "emb = emb / (np.linalg.norm(emb, axis=1, keepdims=True) + 1e-6)\n",
    "\n",
    "# ---------- Webcam loop ----------\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"‚ùå Could not open webcam\")\n",
    "\n",
    "print(\"üé• Press 'q' to quit.\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        tgt_face, tgt_box = detect_and_crop(frame)\n",
    "        if tgt_face is not None:\n",
    "            tgt_in = preprocess_face_256(tgt_face)\n",
    "            result = ss.run([ss_out_name], {ss_face_in: tgt_in, ss_id_in: emb})[0]\n",
    "            swapped = postprocess_face(result)\n",
    "\n",
    "            if BLEND_MODE == \"poisson\":\n",
    "                frame = poisson_blend(frame, swapped, tgt_box)\n",
    "            else:\n",
    "                frame = feather_blend(frame, swapped, tgt_box)\n",
    "    except Exception as e:\n",
    "        # skip frame if detection fails\n",
    "        print(\"‚ö†Ô∏è\", e)\n",
    "\n",
    "    cv2.imshow(\"SimSwap Live\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
